{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72dfa7ec",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1e84",
   "metadata": {},
   "source": [
    "###LLM-based metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ea945",
   "metadata": {},
   "source": [
    "All LLM based metrics in ragas are inherited from MetricWithLLM class. These metrics expects a LLM object to be set before scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c58fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d286807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b7843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "\n",
    "scorer = FactualCorrectness(llm= llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24aff33",
   "metadata": {},
   "source": [
    "###Non-LLM-based metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2e85c",
   "metadata": {},
   "source": [
    "These metrics rely on traditional methods to evaluate the performance of the AI application, such as string similarity, BLEU score, etc. Due to the same, these metrics are known to have a lower correlation with human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d3e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "# Sample 1\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"What is the capital of Germany?\",\n",
    "    retrieved_contexts=[\"Berlin is the capital and largest city of Germany.\"],\n",
    "    response=\"The capital of Germany is Berlin.\",\n",
    "    reference=\"Berlin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SingleTurn Metrics\n",
    "from ragas.metrics import FactualCorrectness\n",
    "\n",
    "scorer = FactualCorrectness()\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MultiTurn Metrics\n",
    "from ragas.metrics import AgentGoalAccuracyWithoutReference\n",
    "from ragas import MultiTurnSample\n",
    "\n",
    "scorer = AgentGoalAccuracyWithoutReference()\n",
    "await scorer.multi_turn_ascore(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b6c91",
   "metadata": {},
   "source": [
    "# Context Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771d6f9",
   "metadata": {},
   "source": [
    "- It is a metric that measures the proportion of relevant chunks in the retrieved_contexts.\n",
    "- It is calculated as the mean of the precision@k for each chunk in the context.\n",
    "- Precision@k is the ratio of the number of relevant chunks at rank k to the total number of chunks at rank k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8353b",
   "metadata": {},
   "source": [
    "##LLM Based Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad9ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Context Precision without referen\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"], \n",
    ")\n",
    "\n",
    "await context_precision.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d420db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Context Precision with reference\n",
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "\n",
    "ref_context_precision = LLMContextPrecisionWithReference(llm= evaluator_llm)\n",
    "\n",
    "sample_2 = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"],\n",
    ")\n",
    "\n",
    "await ref_context_precision.single_turn_ascore(sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58f57f",
   "metadata": {},
   "source": [
    "##Non LLM Based Context Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9decbb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import NonLLMContextPrecisionWithReference\n",
    "\n",
    "NonLLM_context_precision = NonLLMContextPrecisionWithReference()\n",
    "\n",
    "sample_3 = SingleTurnSample(\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"], \n",
    "    reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    ")\n",
    "\n",
    "await NonLLM_context_precision.single_turn_ascore(sample_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2831e2",
   "metadata": {},
   "source": [
    "# Context Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325c2e9",
   "metadata": {},
   "source": [
    "- Context Recall measures how many of the relevant documents (or pieces of information) were successfully retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7573cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Based Context Recall\n",
    "\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import LLMContextRecall\n",
    "\n",
    "sample_4 = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"Paris is the capital of France.\"], \n",
    ")\n",
    "\n",
    "context_recall = LLMContextRecall(llm= evaluator_llm)\n",
    "await context_recall.single_turn_ascore(sample_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c090e760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non LLM Based Context Recall\n",
    "from ragas.metrics import NonLLMContextRecall\n",
    "\n",
    "sample_1 = SingleTurnSample(\n",
    "    retrieved_contexts=[\"Paris is the capital of France.\"], \n",
    "    reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    ")\n",
    "\n",
    "nonllm_context_recall = NonLLMContextRecall()\n",
    "await nonllm_context_recall.single_turn_ascore(sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13968394",
   "metadata": {},
   "source": [
    "# Context Entities Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e49972",
   "metadata": {},
   "source": [
    "ContextEntityRecall metric gives the measure of recall of the retrieved context, based on the number of entities present in both reference and retrieved_contexts relative to the number of entities present in the reference alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa123cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import ContextEntityRecall\n",
    "\n",
    "sample2 = SingleTurnSample(\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"], \n",
    ")\n",
    "\n",
    "CER = ContextEntityRecall(llm= evaluator_llm)\n",
    "await CER.single_turn_ascore(sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225a453",
   "metadata": {},
   "source": [
    "# Noise Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d98a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3333333333333333)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import NoiseSensitivity\n",
    "\n",
    "sample3 = SingleTurnSample(\n",
    "    user_input=\"What is the Life Insurance Corporation of India (LIC) known for?\",\n",
    "    response=\"The Life Insurance Corporation of India (LIC) is the largest insurance company in India, known for its vast portfolio of investments. LIC contributes to the financial stability of the country.\",\n",
    "    reference=\"The Life Insurance Corporation of India (LIC) is the largest insurance company in India, established in 1956 through the nationalization of the insurance industry. It is known for managing a large portfolio of investments.\",\n",
    "    retrieved_contexts=[\n",
    "        \"The Life Insurance Corporation of India (LIC) was established in 1956 following the nationalization of the insurance industry in India.\",\n",
    "        \"LIC is the largest insurance company in India, with a vast network of policyholders and huge investments.\",\n",
    "        \"As the largest institutional investor in India, LIC manages substantial funds, contributing to the financial stability of the country.\",\n",
    "        \"The Indian economy is one of the fastest-growing major economies in the world, thanks to sectors like finance, technology, manufacturing etc.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "ns = NoiseSensitivity(llm= evaluator_llm)\n",
    "await ns.single_turn_ascore(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e248aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = NoiseSensitivity(llm=evaluator_llm, mode=\"irrelevant\")\n",
    "await scorer.single_turn_ascore(sample3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb199de",
   "metadata": {},
   "source": [
    "# Response Relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7123c",
   "metadata": {},
   "source": [
    "- The ResponseRelevancy metric measures how relevant a response is to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367397a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9352738308044745)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import ResponseRelevancy\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "sample4 = SingleTurnSample(\n",
    "        user_input=\"When was the first super bowl?\",\n",
    "        response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "        retrieved_contexts=[\n",
    "            \"The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"llama3.2:1b\"))\n",
    "RR = ResponseRelevancy(llm= evaluator_llm, embeddings=evaluator_embeddings)\n",
    "await RR.single_turn_ascore(sample4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e6af8",
   "metadata": {},
   "source": [
    "# Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd688f",
   "metadata": {},
   "source": [
    "- The Faithfulness metric measures how factually consistent a response is with the retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6faa4e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import Faithfulness\n",
    "\n",
    "sample4 = SingleTurnSample(\n",
    "        user_input=\"When was the first super bowl?\",\n",
    "        response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "        retrieved_contexts=[\n",
    "            \"The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "ff = Faithfulness(llm= evaluator_llm)\n",
    "await ff.single_turn_ascore(sample4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d4b2b",
   "metadata": {},
   "source": [
    "##Faithfullness with HHEM-2.1-Open\n",
    "\n",
    "- Vectara's HHEM-2.1-Open is a classifier model (T5) that is trained to detect hallucinations from LLM generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to install HuggingFace Transformers Library\n",
    "\n",
    "# Faithfullness with HHEM-2.1-Open\n",
    "from ragas.metrics import FaithfulnesswithHHEM\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=\"When was the first super bowl?\",\n",
    "        response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "        retrieved_contexts=[\n",
    "            \"The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "hhem_scorer = FaithfulnesswithHHEM(llm= evaluator_llm)\n",
    "await hhem_scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90395c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_device = \"cuda:0\"\n",
    "my_batch_size = 10\n",
    "\n",
    "scorer = FaithfulnesswithHHEM(device=my_device, batch_size=my_batch_size)\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Complete_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
