{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72dfa7ec",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1e84",
   "metadata": {},
   "source": [
    "###LLM-based metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ea945",
   "metadata": {},
   "source": [
    "All LLM based metrics in ragas are inherited from MetricWithLLM class. These metrics expects a LLM object to be set before scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c58fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d286807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b7843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "\n",
    "scorer = FactualCorrectness(llm= llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24aff33",
   "metadata": {},
   "source": [
    "###Non-LLM-based metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2e85c",
   "metadata": {},
   "source": [
    "These metrics rely on traditional methods to evaluate the performance of the AI application, such as string similarity, BLEU score, etc. Due to the same, these metrics are known to have a lower correlation with human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d3e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "# Sample 1\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"What is the capital of Germany?\",\n",
    "    retrieved_contexts=[\"Berlin is the capital and largest city of Germany.\"],\n",
    "    response=\"The capital of Germany is Berlin.\",\n",
    "    reference=\"Berlin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SingleTurn Metrics\n",
    "from ragas.metrics import FactualCorrectness\n",
    "\n",
    "scorer = FactualCorrectness()\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MultiTurn Metrics\n",
    "from ragas.metrics import AgentGoalAccuracyWithoutReference\n",
    "from ragas import MultiTurnSample\n",
    "\n",
    "scorer = AgentGoalAccuracyWithoutReference()\n",
    "await scorer.multi_turn_ascore(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8353b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Complete_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
